{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmtpos = np.load(\"/home/lukasb/watchmal/IWCD_mPMT_image_positions.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mpmt_image_positions']\n"
     ]
    }
   ],
   "source": [
    "print(list(pmtpos.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(832, 2)\n",
      "[[26  0]\n",
      " [26  1]\n",
      " [26  2]\n",
      " ...\n",
      " [38 17]\n",
      " [39 20]\n",
      " [39 19]]\n"
     ]
    }
   ],
   "source": [
    "print(pmtpos['mpmt_image_positions'].shape)\n",
    "print(pmtpos['mpmt_image_positions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from what I understand, these are the x/y coordinates in the grid for each mPMT ID, given by (tubeId-1)//19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 39], dtype=int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(pmtpos['mpmt_image_positions'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.zeros((40,40))\n",
    "mpmtno = np.zeros((40,40))\n",
    "mpmtno -= 1\n",
    "for mpmt in range(pmtpos['mpmt_image_positions'].shape[0]):\n",
    "    idx = pmtpos['mpmt_image_positions'][mpmt,:]\n",
    "    grid[idx[0],idx[1]] = 1.\n",
    "    mpmtno[idx[0],idx[1]] = mpmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def imshowRdBu(ax,img):\n",
    "    minmax = max(torch.max(img),-torch.min(img))\n",
    "    return ax.imshow(-img,cmap='RdBu',vmin=-minmax,vmax=minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f516cb74750>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshowRdBu(plt, torch.tensor(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f516cafc510>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshowRdBu(plt, torch.tensor(mpmtno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmtpos = np.load(\"/home/lukasb/watchmal/IWCD_mPMT_image_positions.npz\")\n",
    "np.savetxt(\"/home/lukasb/watchmal/IWCD_mPMT_image_positions.csv\", pmtpos['mpmt_image_positions'], fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/lukasb/watchmal/data/IWCDmPMT_4pi_full_tank/h5_opencan/e-/IWCDmPMT_4pi_full_tank_e-_E0to1000MeV_unif-pos-R371-y521cm_4pi-dir_3000evts_1.h5','r')\n",
    "event_data = f['event_data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5140c9b8d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARpUlEQVR4nO3dfZBV5X0H8O+XfRFEUJAFNwsrGlG0VmijDi1NxxBN0TZDkkYHmyY0w4z2hRltMi3EaTTJNI52NMQZO87EiJIpVakmalublhKdqM2gqEBQUAlF3tZdXgVi3Ze7v/5xD86yz3Ph3Hte7rn7fD8zzN77u8+55zmwP869v3vu86OZQURGvlH1noCI5EPJLhIIJbtIIJTsIoFQsosEQskuEohEyU5yPsm3SG4juSytSYlI+ljr5+wkmwC8DeAaALsBvALgRjN7s9I2kyZNss7Ozpr2Jzk49J4TOrr3sBMb9xsz85iN1GDnzp3Yv38/fY81J3jeKwFsM7PtAEDyMQALAFRM9s7OTrz00ksJdilZGlh9lxN74Y6nnNin9G9YWHPnzq34WJKX8R0Adg25vzuKiUgBJUl230sF5z0ByZtIrie5fv/+/Ql2JyJJJEn23QCmDbk/FcDe4YPM7AdmdrmZXT5p0qQEuxORJJK8Z38FwAyS5wHYA2AhgD9JZVaSmq7bFjux9jsf8o5tvsH9QOXqz/6FE9u59Kve7Ttvv8eJlcaefaopSk5qTnYzGyC5BMB/AmgCsMLM3khtZiKSqiRndpjZswCeTWkuIpIhXUEnEgglu0gglOwigUj0nl2Kz1d5b9m3zTvWmlqc2MDEc51Y5w1f8G7ftG+7E1M1vjh0ZhcJhJJdJBBKdpFAKNlFAqECXQNq7d7qxDjQ6x3b2zHLifW3XeB/3q7NTuzQvV9zYm1/cG2FiZ3mj0sh6MwuEgglu0gglOwigVCyiwRCyS4SCFXjG1Dvxp87MX7mptjbNx/p8sb72i91Yh8eeN+Jld4/4N1+1HhdGltkOrOLBELJLhIIJbtIIBK9Zye5A8BRACUAA2Z2eRqTEpH0pVGg+5SZaUH4DIzq+8D/wLgJTqjZc6krAAzs2OLEmjov9I5l76+d2ORPXOTEbO5C7/Z9nljLfvc77gDQP+l8b1yyo5fxIoFImuwG4L9Ivkoy/mc/IpK7pC/j55rZXpKTAawhudXMTvgQOPpP4CYAmDZtmu85RCQHic7sZrY3+tkD4Ccod3YdPkbtn0QKoOZkJzmW5LjjtwF8BoC/SiQidZfkZfwUAD8hefx5/tnMfprKrAQA8NbNX/bGL/pLN+671BUAmkef6cQGB0vesew94sTee9mt5nf8sXdzL1XdiyNJr7ftANxlUESkkPTRm0gglOwigVCyiwRC32cvsBkPP+mND3pirTte8T/J6LFOaNcD93mHdtz6d27s7ocrzm+4lgM7nFj/2dNjby/Z0pldJBBKdpFAKNlFAqFkFwmEkl0kEKrGN6DWvZucWN/0K2Jv3/G1273xgTM7ap4ToMp70enMLhIIJbtIIJTsIoFQsosEQgW6BtT3scsSbZ+0ENd8aJf/eSdo2bEi05ldJBBKdpFAKNlFAqFkFwnEKQt0JFcA+CMAPWZ2aRSbCOBxANMB7ABwg5kdym6aUiQqxDWmOGf2RwDMHxZbBmCtmc0AsDa6LyIFdspkjzq8HBwWXgBgZXR7JYDPpTwvEUlZre/Zp5hZFwBEPydXGkjyJpLrSa7fv1/NXkXqJfMCndo/iRRDrcneTbIdAKKfPelNSUSyUGuyPwNgUXR7EYCn05mOiGTllMlO8lEAvwBwEcndJBcDuAvANSTfAXBNdF9ECuyUn7Ob2Y0VHvp0ynMRkQzpCjqRQCjZRQKR6/fZ7UAXPvzRd06Ijf/9a71jS5MvcGOnT8hkXpXwhVVOrPni33FiafQgf3eJ+26peexo79hqWjIVVcu+bU6sv839N89K687XvPG+zt9O9Lwt+7d7477fkbzXBdCZXSQQSnaRQCjZRQKhZBcJhJJdJBC5VuN5djtGf+XE1kODb/7MOzbvyruPffJLTqy07kknxi2/iL199x03e8eee/+jTqy1e6v/eetcyW45sMMb97V/aul52z928oUpzmjI/rb9j7uvC37XiSWtugPAqA+PuPuq4pOZaqrure+96Y2z1H/inPr/r+Jz6MwuEgglu0gglOwigVCyiwSi7u2frLdyQWG4g/9wizc+8W/vSzaJ/37IG+aYsU5scO5CJ9Z0bJ93+3+Z5haBFr70Q+/YPl9sykzv2KzEvYS1mj7sWRXiKu7PU4zzaXr1X73x0ic+G3tfg6PHxx6bVN85l8QaN9gypuJjOrOLBELJLhIIJbtIIJTsIoGIswbdCpI9JDcPiX2L5B6SG6I/12U7TRFJKk41/hEA9wP40bD4cjO7J+kE3rjnQW985qo/dGLH9vibTEz0VdOvXhx/EhXG/vCc2U7s+m9ucGJWGvRu/4Vd7gIJvqp73ip9emCtlSu5I001VfdKTtuz0Yn1dsxK/LxZqbX9k4g0mCTv2ZeQ3BS9zK//t1ZE5KRqTfYHAHwcwGwAXQDurTRQvd5EiqGmZDezbjMrmdkggAcBXHmSser1JlIANV0uS7L9eBdXAJ8HsPlk4z/aDoZRAx+eEJu56invWN/3d5c/6F8R9L6FbsfoOydc6h279NElTuzFb/yTd+z13xzelh6Y8JW/dmKlcVO82/tU+l5y3Msh01A6oy322Kaj3e72VRxvGprf3+PEBs7s8I71/f1m9XdbTTHOt+pspe+++y7lTaOgeMpkj9o/XQVgEsndAO4AcBXJ2QAMwA4A/hUZRKQwam3/5P/miIgUlq6gEwmEkl0kEEp2kUDk2+sNxGDzif3LKq1U6qug3r/z371jS+PPcWK3b/1N/xya3f5pc5b6LxAcc91X3e23v+4OnOVW7SupVBmupvdZnpdp5ll5T+OTijw/1agK459XfZX31i7/B1597f5PnXx0ZhcJhJJdJBBKdpFAKNlFAlH31WVxaK833OKJDUyY6h1rTa1ubJT/0Hwro46dc43/ed9zi2bmHRlf0weHvPFq2jcV+TvTSRS2uJaCalbk9ammEFeJzuwigVCyiwRCyS4SCCW7SCCU7CKByLUaz8EBZ2XTuL25ADgLX3wU91S4K1W3mw++68T6pl8Rew5JlU5PvlyfbzEH9vd6x1ZaICHt/VdSaZGJPLV2b3VieffRKwKd2UUCoWQXCYSSXSQQcdo/TSP5HMktJN8geUsUn0hyDcl3op9aO16kwOIU6AYAfN3MXiM5DsCrJNcA+DMAa83sLpLLACwDsPRkT2SjmmOvbNq89Xknxrbp3rG+SxHT+P6vD19Y5cTsk19K9JzVqnfRq9L++x+704m1LLwt8f587aqqWSEXgwOJ5zASxGn/1GVmr0W3jwLYAqADwAIAK6NhKwG46zmLSGFU9Z6d5HQAvwVgHYApx9eOj35OTntyIpKe2MlO8gwATwK41cyOVLGd2j+JFECsZCfZgnKirzKzH0fhbpLt0ePtAHp826r9k0gxxOkIQ5SbQmwxs+8NeegZAIsA3BX9fDrNiQ3MvCr2WF9rnTS+/+uTdzGukYy5dpETs18f8I4tjT079vNWVYzzyOp3odHEqcbPBfBlAL8kuSGK3YZykq8muRjATgDXZzNFEUlDnPZPLwJghYc/ne50RCQruoJOJBBKdpFAKNlFAlH/1WWrMKrvA2+cpb6cZyI+9b6MV05OZ3aRQCjZRQKhZBcJhJJdJBANVaAbbD3dGw9x8UAppkrtvdJYaDQpndlFAqFkFwmEkl0kEEp2kUAo2UUCUdhqvO/S2ErV+JHK17YI0KcPRVap6t66d5MT6/vYZVlP5wQ6s4sEQskuEgglu0ggkrR/+hbJPSQ3RH+uy366IlKrJO2fAGC5md2TxcSKUIxrPrTLiQ1MmJbb/lWIK7bmg+86sYGJ53rH5l2M84mz4GQXgOOdX46SPN7+SUQaSJL2TwCwhOQmkivUxVWk2JK0f3oAwMcBzEb5zH9vhe3U/kmkAGpu/2Rm3WZWMrNBAA8CuNK3rdo/iRRDnGq8t/3T8T5vkc8D8DdEF5FCSNL+6UaSswEYgB0Abs5khkO0dvn/P8mql5ev8t6yb5sT62+7wLt98/t73OessAJrNc9bjeYjXe4cxrd7Rkq1KlXeiypJ+6dn05+OiGRFV9CJBELJLhIIJbtIIAr7fXafrApx1aimaFZNO6Q0inHeOdS5GNe08afeeGnW/JxnIjqziwRCyS4SCCW7SCCU7CKBULKLBKKhqvGSv6QLeKjqXhw6s4sEQskuEgglu0gglOwigVCBTk4qz9V0JVs6s4sEQskuEgglu0gg4iw4OZrkyyQ3Ru2fvh3FzyO5juQ7JB8n2Zr9dEWkVnHO7L0A5pnZLJTXiJ9Pcg6Au1Fu/zQDwCEAi7Obpogkdcpkt7Jj0d2W6I8BmAfgiSi+EsDnMpmhiKQibpOIpmgZ6R4AawD8CsBhMxuIhuyG+r+JFFqsZI86v8wGMBXlzi8X+4b5tlX7J5FiqKoab2aHATwPYA6As0gevyhnKoC9FbZR+yeRAohTjW8jeVZ0ewyAqwFsAfAcgC9GwxYBeDqrSYpIcnEul20HsJJkE8r/Oaw2s38j+SaAx0j+PYDXUe4HJyPMaXs2OrHejll1mIkkFaf90yaUe7IPj29Hhc6tIlI8uoJOJBBKdpFAKNlFAqHvs49wTcf2ObHSGW2xt8+qGNfS87YT6598YSb7kjKd2UUCoWQXCYSSXSQQSnaRQCjZRQKhavwIV03lPVej9KuXN53ZRQKhZBcJhJJdJBBKdpFAqEoiddE/6Xwn1nS02zu2NG5K1tMJgs7sIoFQsosEQskuEogk7Z8eIfm/JDdEf2ZnP10RqVWcAt3x9k/HSLYAeJHkf0SP/Y2ZPXGSbUWkIOIsOGkAfO2fZIRp7d7qxPqmzMxt/6q6Z6um9k9mti566LskN5FcTvK0zGYpIonV1P6J5KUAvgFgJoArAEwEsNS3rdo/iRRDre2f5ptZV9ThtRfAw6iwhrzaP4kUQ63tn7aSbI9iRLld8+YsJyoiySRp//Qzkm0ACGADgD/PcJ6SgzyLcZK/JO2f5mUyIxHJhK6gEwmEkl0kEEp2kUAo2UUCoWQXCYSSXSQQSnaRQCjZRQKhZBcJhJJdJBBKdpFAKNlFAqFkFwmEkl0kEEp2kUAo2UUCoWQXCYSSXSQQSnaRQCjZRQLBcnennHZG7gPwbnR3EoCR2DVCx9V4RtKxnWtmbb4Hck32E3ZMrjezy+uy8wzpuBrPSD62ofQyXiQQSnaRQNQz2X9Qx31nScfVeEbysX2kbu/ZRSRfehkvEojck53kfJJvkdxGclne+08TyRUke0huHhKbSHINyXeinxPqOcdakJxG8jmSW0i+QfKWKN7Qx0ZyNMmXSW6MjuvbUfw8kuui43qcZGu955qFXJM96gT7jwCuBXAJgBtJXpLnHFL2CID5w2LLAKw1sxkA1kb3G80AgK+b2cUA5gD4q+jfqdGPrRfAPDObBWA2gPkk5wC4G8Dy6LgOAVhcxzlmJu8z+5UAtpnZdjPrA/AYgAU5zyE1ZvZzAAeHhRcAWBndXoly7/qGYmZdZvZadPsogC0AOtDgx2Zlx6K7LdEfAzAPwBNRvOGOK668k70DwK4h93dHsZFkipl1AeWkATC5zvNJhOR0lFt2r8MIODaSTSQ3AOgBsAbArwAcNrOBaMhI/J0EkH+y0xPTxwEFRfIMAE8CuNXMjtR7Pmkws5KZzQYwFeVXmhf7huU7q3zkney7AUwbcn8qgL05zyFr3STbASD62VPn+dSEZAvKib7KzH4chUfEsQGAmR0G8DzKNYmzSDZHD43E30kA+Sf7KwBmRNXPVgALATyT8xyy9gyARdHtRQCeruNcakKSAB4CsMXMvjfkoYY+NpJtJM+Kbo8BcDXK9YjnAHwxGtZwxxVX7hfVkLwOwPcBNAFYYWbfzXUCKSL5KICrUP7WVDeAOwA8BWA1gE4AOwFcb2bDi3iFRvL3ALwA4JcABqPwbSi/b2/YYyN5GcoFuCaUT3Srzew7JM9HuVg8EcDrAP7UzHrrN9Ns6Ao6kUDoCjqRQCjZRQKhZBcJhJJdJBBKdpFAKNlFAqFkFwmEkl0kEP8P8JsPd5VcFjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshowRdBu(plt, torch.tensor(event_data[2,:,:,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load a network and say if we can compute the gradient of the loss on the data\n",
    "\n",
    "from `20200708-04-IWCD-SmallerResNetGeom-timeCmplx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def geometricPad(grid, pad=1):\n",
    "  M = grid.shape[2]; # 0:batchsize, 1:channels, 2:width, 3:height\n",
    "  M_new = pad+M+pad;\n",
    "  new_shape = (grid.shape[0], grid.shape[1], M_new, M_new)\n",
    "  grid_new = grid.new_zeros(new_shape);\n",
    "  grid_new[:,:,pad:M+pad,pad:M+pad] = grid;\n",
    "  grid_new[:,:,0:pad,pad:(M+pad)] = grid[:,:,:,0:pad].flip(-1).transpose(-1,-2);\n",
    "  grid_new[:,:,pad:(M+pad),0:pad] = grid[:,:,0:pad,:].flip(-2).transpose(-1,-2);\n",
    "  grid_new[:,:,(M+pad):(M+pad+pad),(pad):(M+pad)] = grid[:,:,:,(M-pad):].flip(-1).transpose(-1,-2);\n",
    "  grid_new[:,:,pad:(M+pad),(M+pad):(M+pad+pad)] = grid[:,:,(M-pad):,:].flip(-2).transpose(-1,-2);\n",
    "  return(grid_new);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/lukasb/watchmal/data/IWCDmPMT_4pi_full_tank/h5_topo/IWCDmPMT_4pi_full_tank_e-_E0to1000MeV_unif-pos-R371-y521cm_4pi-dir_3000evts_1.h5','r')\n",
    "event_data = f['event_data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshowRdBu(ax,img):\n",
    "    minmax = max(torch.max(img),-torch.min(img))\n",
    "    return ax.imshow(-img,cmap='RdBu',vmin=-minmax,vmax=minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class H5Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, files, transform=None, flavour=None, limit_num_files=0, start_fraction=0., use_fraction=1.0):\n",
    "        \"\"\"                                                                                                                                             \n",
    "        Args: data_dirs ... a list of data directories to find files (up to 10 files read from each dir)                                                \n",
    "              transform ... a function applied to pre-process data                                                                                      \n",
    "              flavour ..... a string that is required to be present in the filename                                                                     \n",
    "              limit_num_files ... an integer limiting number of files to be taken per data directory                                                    \n",
    "              start_fraction ... a floating point fraction (0.0=>1.0) to specify which entry to start reading (per file)                                \n",
    "              use_fraction ..... a floating point fraction (0.0=>1.0) to specify how much fraction of a file to be read out (per file)                  \n",
    "        \"\"\"\n",
    "        self._transform = transform\n",
    "        self._files = []\n",
    "\n",
    "        # Check input fractions makes sense                                                                                                             \n",
    "        assert start_fraction >= 0. and start_fraction < 1.\n",
    "        assert use_fraction > 0. and use_fraction <= 1.\n",
    "        assert (start_fraction + use_fraction) <= 1.\n",
    "\n",
    "        # Load files (up to 10) from each directory in data_dirs list                                                                                   \n",
    "        # for d in data_dirs:\n",
    "        #     file_list = [ os.path.join(d,f) for f in os.listdir(d) if flavour is None or flavour in f ]\n",
    "        #     if limit_num_files: file_list = file_list[0:limit_num_files]\n",
    "        #     self._files += file_list\n",
    "        self._files = files\n",
    "\n",
    "        self._file_handles = [None] * len(self._files)\n",
    "        self._event_to_file_index  = []\n",
    "        self._event_to_entry_index = []\n",
    "        import h5py\n",
    "        for file_index, file_name in enumerate(self._files):\n",
    "            f = h5py.File(file_name,mode='r')\n",
    "            data_size = f['event_data'].shape[0]\n",
    "            start_entry = int(start_fraction * data_size)\n",
    "            num_entries = int(use_fraction * data_size)\n",
    "            self._event_to_file_index += [file_index] * num_entries\n",
    "            self._event_to_entry_index += range(start_entry, start_entry+num_entries)\n",
    "            f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._event_to_file_index)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        file_index = self._event_to_file_index[idx]\n",
    "        entry_index = self._event_to_entry_index[idx]\n",
    "        if self._file_handles[file_index] is None:\n",
    "            import h5py\n",
    "            self._file_handles[file_index] = h5py.File(self._files[file_index],mode='r')\n",
    "        fh = self._file_handles[file_index]\n",
    "        label = fh['labels'][entry_index]\n",
    "        #labelTranslation = [-1,0,1,-1,2] # make sure that labels 1,2,4 get values 0,1,2\n",
    "        if label == 1: # electron\n",
    "            label = 0\n",
    "        elif label == 2: # muon\n",
    "            label = 1\n",
    "        elif label == 0: # gamma\n",
    "            label = 2\n",
    "        else:\n",
    "            print('Unknown label', label, 'for entry_index', entry_index, 'treating as label=0')\n",
    "            label = 0\n",
    "        \n",
    "        # try:\n",
    "        #     label = labelTranslation[label]\n",
    "        # except IndexError:\n",
    "        #     print('IndexError at entry', entry_index, 'label in file was', fh['labels'][entry_index], 'translations are', labelTranslation)\n",
    "        #     raise\n",
    "        \n",
    "        event_data = fh['event_data'][entry_index]\n",
    "        # convert event data to complex rep\n",
    "        evQ = event_data[:,:,0]\n",
    "        evT = event_data[:,:,1]\n",
    "        evR = np.power(evQ,0.25);\n",
    "        evA = 2*np.pi*(evT-960.)/(1900.-600.)\n",
    "        evX = evR*np.cos(evA);\n",
    "        evY = evR*np.sin(evA);\n",
    "        return np.stack([evX,evY],2),label,idx,fh['positions'][entry_index,0],fh['directions'][entry_index,0],np.sum(fh['energies'][entry_index,:])\n",
    "        # the ,0 in positions and directions selects the pos/dir for the first track (in case of gamma)\n",
    "        # thus positions and directions are just np arrays with 3 elements\n",
    "\n",
    "def HKCollate(batch):\n",
    "    data  = np.stack([sample[0] for sample in batch])\n",
    "    label = [sample[1] for sample in batch]\n",
    "    idx   = [sample[2] for sample in batch]\n",
    "    pos   = np.stack([sample[3] for sample in batch])\n",
    "    direc = np.stack([sample[4] for sample in batch])\n",
    "    ene   = np.stack([sample[5] for sample in batch])\n",
    "    return data,label,idx,pos,direc,ene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdir = '/home/lukasb/watchmal/data/IWCDmPMT_4pi_full_tank/h5_topo'\n",
    "pnames = ('e-','mu-')\n",
    "files = ['%s/%s/IWCDmPMT_4pi_full_tank_%s_E0to1000MeV_unif-pos-R371-y521cm_4pi-dir_3000evts_%d.h5' % (mcdir,pname,pname,bch+100) for bch in range(60) for pname in pnames]\n",
    "\n",
    "train_ds = H5Dataset(files,start_fraction=0.0,use_fraction=0.9);\n",
    "test_ds  = H5Dataset(files,start_fraction=0.9,use_fraction=0.1);\n",
    "\n",
    "# for training\n",
    "train_loader=DataLoader(train_ds,batch_size=32,shuffle=True,num_workers=4,collate_fn=HKCollate)\n",
    "# for validation\n",
    "test_loader =DataLoader( test_ds,batch_size=64,shuffle=True,num_workers=2,collate_fn=HKCollate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# based on https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "class BasicGeomBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicGeomBlock, self).__init__()\n",
    "        \n",
    "        self.pad = 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=2*self.pad+1, stride=stride, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=2*self.pad+1,\n",
    "                               stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(geometricPad(x,self.pad))))\n",
    "        out = self.bn2(self.conv2(geometricPad(out,self.pad)))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetGeom(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=3):\n",
    "        super(ResNetGeom, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        overall_in_planes = 2 ## this has been modified to include time\n",
    "        self.pad = 1\n",
    "        \n",
    "        # (1,126,126)\n",
    "        self.conv1 = nn.Conv2d(overall_in_planes, 32, kernel_size=2*self.pad+1,\n",
    "                               stride=2, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # outsize = floor[(126+2*self.pad-3)/stride + 1]\n",
    "        # so for stride=1 we have 126,\n",
    "        #              =2          63 = floor(63.5)\n",
    "        # the padding is done by geometricPad\n",
    "        # thus (16,63,63)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2*self.pad+1,\n",
    "                               stride=2, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # outsize = floor[(63+2*self.pad-3)/stride + 1]\n",
    "        # so for stride=1 we have 63,\n",
    "        #              =2         32\n",
    "        # thus (64,32,32)\n",
    "        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n",
    "        #      (64,32,32)\n",
    "        self.layer2 = self._make_layer(block,  64, num_blocks[1], stride=2)\n",
    "        #      (64,16,16)\n",
    "        self.layer3 = self._make_layer(block,  64, num_blocks[2], stride=2)\n",
    "        #      (64, 8, 8)\n",
    "        self.layer4 = self._make_layer(block, 128, num_blocks[3], stride=2)\n",
    "        #      (128,4, 4)\n",
    "        self.convbn5 = nn.Sequential(\n",
    "            nn.Conv2d(128,128,kernel_size=4,stride=1,padding=0),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        #      (128,1, 1)\n",
    "        # transform to 128, then\n",
    "        self.linear1 = nn.Linear(int(128*block.expansion),   int(128*block.expansion/2))\n",
    "        self.linear2 = nn.Linear(int(128*block.expansion/2), int(128*block.expansion/4))\n",
    "        self.linear3 = nn.Linear(int(128*block.expansion/4), int(128*block.expansion/8))\n",
    "        self.linear4 = nn.Linear(int(128*block.expansion/8), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(geometricPad(x,self.pad))))\n",
    "        out = F.relu(self.bn2(self.conv2(geometricPad(out,self.pad))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.relu(self.convbn5(out))\n",
    "        #out = F.avg_pool2d(out, out.shape[2:4])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.linear1(out))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = F.relu(self.linear3(out))\n",
    "        out = self.linear4(out)\n",
    "        return out\n",
    "\n",
    "#    # I'm not sure why I need to implement cpu/cuda myself, train works somehow\n",
    "#    \n",
    "#    def cpu(self):\n",
    "#        super(GeomCNN, self).cpu()\n",
    "#        for module in self._feature:\n",
    "#            module.cpu()\n",
    "#        for module in self._classifier:\n",
    "#            module.cpu()\n",
    "#        return self\n",
    "#    \n",
    "#    def cuda(self):\n",
    "#        super(GeomCNN, self).cuda()\n",
    "#        for module in self._feature:\n",
    "#            module.cuda()\n",
    "#        for module in self._classifier:\n",
    "#            module.cuda()\n",
    "#        return self\n",
    "\n",
    "def ResNetGeom18(num_classes):\n",
    "    return ResNetGeom(BasicGeomBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(blob,train=True):\n",
    "    \"\"\"\n",
    "       Args: blob should have attributes, net, criterion, softmax, data, label\n",
    "       Returns: a dictionary of predicted labels, softmax, loss, and accuracy\n",
    "    \"\"\"\n",
    "    with torch.set_grad_enabled(train):\n",
    "        # Prediction\n",
    "        blob.formatted_data = torch.as_tensor(blob.data).cuda()#[torch.as_tensor(d).cuda() for d in blob.data]\n",
    "        blob.formatted_data = blob.formatted_data.permute(0,3,1,2)\n",
    "        prediction = blob.net(blob.formatted_data)\n",
    "        # Training\n",
    "        loss,acc=-1,-1\n",
    "        if blob.label is not None:\n",
    "            label = torch.as_tensor(blob.label).type(torch.LongTensor).cuda()#[torch.as_tensor(l).cuda() for l in blob.label]\n",
    "            #label = torch.as_tensor(blob.label).type(torch.FloatTensor).cuda()#[torch.as_tensor(l).cuda() for l in blob.label]\n",
    "            label.requires_grad = False\n",
    "            loss = blob.criterion(prediction,label)\n",
    "        blob.loss = loss\n",
    "        \n",
    "        softmax    = blob.softmax(prediction).cpu().detach().numpy()\n",
    "        prediction = torch.argmax(prediction,dim=-1)\n",
    "        accuracy   = (prediction == label).sum().item() / float(prediction.nelement())\n",
    "        # mse        = blob.mse(prediction,label).cpu().detach().numpy()\n",
    "        # accuracy   = np.sqrt(mse.mean()).item()\n",
    "        prediction = prediction.cpu().detach().numpy()\n",
    "        \n",
    "        return {'prediction' : prediction,\n",
    "                'softmax'    : softmax,\n",
    "                'loss'       : loss.cpu().detach().item(),\n",
    "                'accuracy'   : accuracy}\n",
    "\n",
    "def backward(blob):\n",
    "    blob.optimizer.zero_grad()  # Reset gradients accumulation\n",
    "    blob.loss.backward()\n",
    "    blob.optimizer.step()\n",
    "\n",
    "def save_state(blob):\n",
    "    # Output file name\n",
    "    filename = '%s-%d.ckpt' % (blob.prefix, blob.iteration)\n",
    "    # Save parameters\n",
    "    # 0+1) iteration counter + optimizer state => in case we want to \"continue training\" later\n",
    "    # 2) network weight\n",
    "    torch.save({\n",
    "        'global_epoch': blob.epoch,\n",
    "        'global_step': blob.iteration,\n",
    "        'optimizer': blob.optimizer.state_dict(),\n",
    "        'state_dict': blob.net.state_dict()\n",
    "        }, filename)\n",
    "    return filename\n",
    "\n",
    "def restore_state(blob, iteration):\n",
    "    # Open a file in read-binary mode\n",
    "    weight_file = '%s-%d.ckpt' % (blob.prefix, iteration)\n",
    "    with open(weight_file, 'rb') as f:\n",
    "        # torch interprets the file, then we can access using string keys\n",
    "        checkpoint = torch.load(f)\n",
    "        # load network weights\n",
    "        blob.net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        # if optimizer is provided, load the state of the optimizer\n",
    "        if blob.optimizer is not None:\n",
    "            blob.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        # load iteration count\n",
    "        blob.epoch     = checkpoint['global_epoch']\n",
    "        blob.iteration = checkpoint['global_step']\n",
    "\n",
    "# weight_file = save_state(blob, '20190819-02-DeepTaylor-01-BatchNorm')\n",
    "# print('Saved to', weight_file)\n",
    "\n",
    "\n",
    "# # Recreate the network (i.e. initialize)\n",
    "# blob.net=LeNet().cuda()\n",
    "# # Get one batch of data to test\n",
    "# blob.data, blob.label = next(iter(train_loader))\n",
    "# # Run forward function\n",
    "# res = forward(blob,True)\n",
    "# # Report\n",
    "# print('Accuracy:',res['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# # Restore the state\n",
    "# restore_state(weight_file,blob)\n",
    "# # Run the forward function\n",
    "# res = forward(blob,True)\n",
    "# # Report\n",
    "# print('Accuracy',res['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLOB:\n",
    "    pass\n",
    "blob=BLOB()\n",
    "blob.net       = ResNetGeom18(2).cuda() # construct ResNet for 2 class classification, use GPU\n",
    "# just the training weights is ~700MiB\n",
    "blob.criterion = torch.nn.CrossEntropyLoss() # use softmax loss to define an error\n",
    "blob.optimizer = torch.optim.Adam(blob.net.parameters()) # use Adam optimizer algorithm\n",
    "blob.softmax   = torch.nn.Softmax(dim=1) # not for training, but softmax score for each class\n",
    "blob.prefix    = '20200708-04-IWCD-SmallResNetGeom-timeCmplx-01-e-mu'\n",
    "blob.epoch     = 0.\n",
    "blob.iteration = 0\n",
    "blob.data      = None # data for training/analysis\n",
    "blob.label     = None # label for training/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_state(blob, 40500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nplot = 6\n",
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "\n",
    "blob.net.eval()\n",
    "test_data = next(iter(test_loader))\n",
    "blob.data,blob.label = test_data[0:2]\n",
    "blob.data  = blob.data[0:Nplot,:,:,:]\n",
    "blob.label = blob.label[0:Nplot]\n",
    "res = forward(blob,True)\n",
    "\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        #im = axes[2*ev+qt].imshow(blob.data[ev,:,:,qt])\n",
    "        imshowRdBu(axes[2*ev+qt], torch.as_tensor(blob.data[ev,:,:,qt]))\n",
    "        labelNames = ['e','μ']\n",
    "        correct = (blob.label[ev] == res['prediction'][ev])\n",
    "        if qt == 0:\n",
    "            axes[2*ev+qt].set_title('%s pred: %s, true: %s' % ('✔︎' if correct else '✖︎', labelNames[blob.label[ev]], labelNames[res['prediction'][ev]]))\n",
    "    #cbar = fig.colorbar(im, ax=axes[0])\n",
    "plt.show()\n",
    "\n",
    "#del test_data\n",
    "#del blob.data\n",
    "#del blob.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blob.formatted_data.shape)\n",
    "print(blob.formatted_data.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.net.conv1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.formatted_data.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(blob,train=True,data_requires_grad=False):\n",
    "    \"\"\"\n",
    "       Args: blob should have attributes, net, criterion, softmax, data, label\n",
    "       Returns: a dictionary of predicted labels, softmax, loss, and accuracy\n",
    "    \"\"\"\n",
    "    with torch.set_grad_enabled(train):\n",
    "        # Prediction\n",
    "        blob.formatted_data = torch.as_tensor(blob.data).cuda()#[torch.as_tensor(d).cuda() for d in blob.data]\n",
    "        blob.formatted_data = blob.formatted_data.permute(0,3,1,2)\n",
    "        blob.formatted_data.requires_grad = data_requires_grad\n",
    "        prediction = blob.net(blob.formatted_data)\n",
    "        # Training\n",
    "        loss,acc=-1,-1\n",
    "        if blob.label is not None:\n",
    "            label = torch.as_tensor(blob.label).type(torch.LongTensor).cuda()#[torch.as_tensor(l).cuda() for l in blob.label]\n",
    "            #label = torch.as_tensor(blob.label).type(torch.FloatTensor).cuda()#[torch.as_tensor(l).cuda() for l in blob.label]\n",
    "            label.requires_grad = False\n",
    "            loss = blob.criterion(prediction,label)\n",
    "        blob.loss = loss\n",
    "        \n",
    "        softmax    = blob.softmax(prediction).cpu().detach().numpy()\n",
    "        prediction = torch.argmax(prediction,dim=-1)\n",
    "        accuracy   = (prediction == label).sum().item() / float(prediction.nelement())\n",
    "        # mse        = blob.mse(prediction,label).cpu().detach().numpy()\n",
    "        # accuracy   = np.sqrt(mse.mean()).item()\n",
    "        prediction = prediction.cpu().detach().numpy()\n",
    "        \n",
    "        return {'prediction' : prediction,\n",
    "                'softmax'    : softmax,\n",
    "                'loss'       : loss.cpu().detach().item(),\n",
    "                'accuracy'   : accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forward(blob,True,data_requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.formatted_data.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blob.formatted_data.shape)\n",
    "print(blob.formatted_data.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        #im = axes[2*ev+qt].imshow(blob.data[ev,:,:,qt])\n",
    "        imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "        labelNames = ['e','μ']\n",
    "        correct = (blob.label[ev] == res['prediction'][ev])\n",
    "        if qt == 0:\n",
    "            axes[2*ev+qt].set_title('%s pred: %s, true: %s' % ('✔︎' if correct else '✖︎', labelNames[blob.label[ev]], labelNames[res['prediction'][ev]]))\n",
    "    #cbar = fig.colorbar(im, ax=axes[0])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrows = 5\n",
    "for r in range(Nrows):\n",
    "    Nplot = 6\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "\n",
    "    blob.net.eval()\n",
    "    test_data = next(iter(test_loader))\n",
    "    blob.data,blob.label = test_data[0:2]\n",
    "    blob.data  = blob.data[0:Nplot,:,:,:]\n",
    "    blob.label = blob.label[0:Nplot]\n",
    "    res = forward(blob,True,data_requires_grad=True)\n",
    "    blob.loss.backward()\n",
    "\n",
    "    for ev in range(int(Nplot/2)):\n",
    "        for qt in range(2):\n",
    "            #im = axes[2*ev+qt].imshow(blob.data[ev,:,:,qt])\n",
    "            imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "            labelNames = ['e','μ']\n",
    "            correct = (blob.label[ev] == res['prediction'][ev])\n",
    "            if qt == 0:\n",
    "                axes[2*ev+qt].set_title('%s pred: %s, true: %s' % ('✔︎' if correct else '✖︎', labelNames[blob.label[ev]], labelNames[res['prediction'][ev]]))\n",
    "        #cbar = fig.colorbar(im, ax=axes[0])\n",
    "    plt.show()\n",
    "\n",
    "    del test_data\n",
    "    del blob.data\n",
    "    del blob.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can probably run the NN layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbn1 = F.relu(blob.net.bn1(blob.net.conv1(geometricPad(blob.formatted_data,blob.net.pad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = torch.zeros(convbn1.shape)\n",
    "activation[:,0,10,10] = 1.\n",
    "convbn1.backward(activation.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.formatted_data.grad.zero_()\n",
    "convbn1 = F.relu(blob.net.bn1(blob.net.conv1(geometricPad(blob.formatted_data,blob.net.pad))))\n",
    "activation = torch.zeros(convbn1.shape)\n",
    "activation[:,0,:,:] = 1.\n",
    "convbn1.backward(activation.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.formatted_data.grad.zero_()\n",
    "\n",
    "x = blob.formatted_data\n",
    "out = F.relu(blob.net.bn1(blob.net.conv1(geometricPad(x,blob.net.pad))))\n",
    "out = F.relu(blob.net.bn2(blob.net.conv2(geometricPad(out,blob.net.pad))))\n",
    "out = blob.net.layer1(out)\n",
    "\n",
    "activation = torch.zeros(out.shape)\n",
    "activation[:,3,10,10] = 1.\n",
    "out.backward(activation.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.formatted_data.grad.zero_()\n",
    "\n",
    "x = blob.formatted_data\n",
    "out = F.relu(blob.net.bn1(blob.net.conv1(geometricPad(x,blob.net.pad))))\n",
    "out = F.relu(blob.net.bn2(blob.net.conv2(geometricPad(out,blob.net.pad))))\n",
    "out = blob.net.layer1(out)\n",
    "out = blob.net.layer2(out)\n",
    "out = blob.net.layer3(out)\n",
    "out = blob.net.layer4(out)\n",
    "out = F.relu(blob.net.convbn5(out))\n",
    "out = out.view(out.size(0), -1)\n",
    "\n",
    "activation = torch.zeros(out.shape)\n",
    "activation[:,4] = 1.\n",
    "out.backward(activation.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "for ev in range(int(Nplot/2)):\n",
    "    for qt in range(2):\n",
    "        imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = ['e','mu']\n",
    "for particle in [0,1]:\n",
    "    blob.formatted_data.grad.zero_()\n",
    "    prediction = blob.net(blob.formatted_data)\n",
    "\n",
    "    activation = torch.zeros(prediction.shape)\n",
    "    activation[:,particle] = 1.\n",
    "    prediction.backward(activation.cuda())\n",
    "\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "    for ev in range(int(Nplot/2)):\n",
    "        for qt in range(2):\n",
    "            imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "    axes[0].set_title('d/dx p(%s)' % pname[particle])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe more insightful is the case with 3 PIDs: `20200708-03-IWCD-SmallerResNetGeom-emugamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class H5Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, files, transform=None, flavour=None, limit_num_files=0, start_fraction=0., use_fraction=1.0):\n",
    "        \"\"\"                                                                                                                                             \n",
    "        Args: data_dirs ... a list of data directories to find files (up to 10 files read from each dir)                                                \n",
    "              transform ... a function applied to pre-process data                                                                                      \n",
    "              flavour ..... a string that is required to be present in the filename                                                                     \n",
    "              limit_num_files ... an integer limiting number of files to be taken per data directory                                                    \n",
    "              start_fraction ... a floating point fraction (0.0=>1.0) to specify which entry to start reading (per file)                                \n",
    "              use_fraction ..... a floating point fraction (0.0=>1.0) to specify how much fraction of a file to be read out (per file)                  \n",
    "        \"\"\"\n",
    "        self._transform = transform\n",
    "        self._files = []\n",
    "\n",
    "        # Check input fractions makes sense                                                                                                             \n",
    "        assert start_fraction >= 0. and start_fraction < 1.\n",
    "        assert use_fraction > 0. and use_fraction <= 1.\n",
    "        assert (start_fraction + use_fraction) <= 1.\n",
    "\n",
    "        # Load files (up to 10) from each directory in data_dirs list                                                                                   \n",
    "        # for d in data_dirs:\n",
    "        #     file_list = [ os.path.join(d,f) for f in os.listdir(d) if flavour is None or flavour in f ]\n",
    "        #     if limit_num_files: file_list = file_list[0:limit_num_files]\n",
    "        #     self._files += file_list\n",
    "        self._files = files\n",
    "\n",
    "        self._file_handles = [None] * len(self._files)\n",
    "        self._event_to_file_index  = []\n",
    "        self._event_to_entry_index = []\n",
    "        import h5py\n",
    "        for file_index, file_name in enumerate(self._files):\n",
    "            f = h5py.File(file_name,mode='r')\n",
    "            data_size = f['event_data'].shape[0]\n",
    "            start_entry = int(start_fraction * data_size)\n",
    "            num_entries = int(use_fraction * data_size)\n",
    "            self._event_to_file_index += [file_index] * num_entries\n",
    "            self._event_to_entry_index += range(start_entry, start_entry+num_entries)\n",
    "            f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._event_to_file_index)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        file_index = self._event_to_file_index[idx]\n",
    "        entry_index = self._event_to_entry_index[idx]\n",
    "        if self._file_handles[file_index] is None:\n",
    "            import h5py\n",
    "            self._file_handles[file_index] = h5py.File(self._files[file_index],mode='r')\n",
    "        fh = self._file_handles[file_index]\n",
    "        label = fh['labels'][entry_index]\n",
    "        #labelTranslation = [-1,0,1,-1,2] # make sure that labels 1,2,4 get values 0,1,2\n",
    "        if label == 1: # electron\n",
    "            label = 0\n",
    "        elif label == 2: # muon\n",
    "            label = 1\n",
    "        elif label == 0: # gamma\n",
    "            label = 2\n",
    "        else:\n",
    "            print('Unknown label', label, 'for entry_index', entry_index, 'treating as label=0')\n",
    "            label = 0\n",
    "        \n",
    "        # try:\n",
    "        #     label = labelTranslation[label]\n",
    "        # except IndexError:\n",
    "        #     print('IndexError at entry', entry_index, 'label in file was', fh['labels'][entry_index], 'translations are', labelTranslation)\n",
    "        #     raise\n",
    "        \n",
    "        event_data = fh['event_data'][entry_index]\n",
    "        return event_data[:,:,0:1],label,idx,fh['positions'][entry_index,0],fh['directions'][entry_index,0],np.sum(fh['energies'][entry_index,:])\n",
    "        # the ,0 in positions and directions selects the pos/dir for the first track (in case of gamma)\n",
    "        # thus positions and directions are just np arrays with 3 elements\n",
    "\n",
    "def HKCollate(batch):\n",
    "    data  = np.stack([sample[0] for sample in batch])\n",
    "    label = [sample[1] for sample in batch]\n",
    "    idx   = [sample[2] for sample in batch]\n",
    "    pos   = np.stack([sample[3] for sample in batch])\n",
    "    direc = np.stack([sample[4] for sample in batch])\n",
    "    ene   = np.stack([sample[5] for sample in batch])\n",
    "    return data,label,idx,pos,direc,ene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdir = '/home/lukasb/watchmal/data/IWCDmPMT_4pi_full_tank/h5_topo'\n",
    "pnames = ('e-','mu-','gamma')\n",
    "files = ['%s/%s/IWCDmPMT_4pi_full_tank_%s_E0to1000MeV_unif-pos-R371-y521cm_4pi-dir_3000evts_%d.h5' % (mcdir,pname,pname,bch+100) for bch in range(60) for pname in pnames]\n",
    "\n",
    "train_ds = H5Dataset(files,start_fraction=0.0,use_fraction=0.9);\n",
    "test_ds  = H5Dataset(files,start_fraction=0.9,use_fraction=0.1);\n",
    "\n",
    "# for training\n",
    "train_loader=DataLoader(train_ds,batch_size=32,shuffle=True,num_workers=4,collate_fn=HKCollate)\n",
    "# for validation\n",
    "test_loader =DataLoader( test_ds,batch_size=64,shuffle=True,num_workers=2,collate_fn=HKCollate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# based on https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py\n",
    "\n",
    "class BasicGeomBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicGeomBlock, self).__init__()\n",
    "        \n",
    "        self.pad = 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=2*self.pad+1, stride=stride, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=2*self.pad+1,\n",
    "                               stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(geometricPad(x,self.pad))))\n",
    "        out = self.bn2(self.conv2(geometricPad(out,self.pad)))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetGeom(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=3):\n",
    "        super(ResNetGeom, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        overall_in_planes = 1\n",
    "        self.pad = 1\n",
    "        \n",
    "        # (1,126,126)\n",
    "        self.conv1 = nn.Conv2d(overall_in_planes, 32, kernel_size=2*self.pad+1,\n",
    "                               stride=2, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # outsize = floor[(126+2*self.pad-3)/stride + 1]\n",
    "        # so for stride=1 we have 126,\n",
    "        #              =2          63 = floor(63.5)\n",
    "        # the padding is done by geometricPad\n",
    "        # thus (16,63,63)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2*self.pad+1,\n",
    "                               stride=2, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # outsize = floor[(63+2*self.pad-3)/stride + 1]\n",
    "        # so for stride=1 we have 63,\n",
    "        #              =2         32\n",
    "        # thus (64,32,32)\n",
    "        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n",
    "        #      (64,32,32)\n",
    "        self.layer2 = self._make_layer(block,  64, num_blocks[1], stride=2)\n",
    "        #      (64,16,16)\n",
    "        self.layer3 = self._make_layer(block,  64, num_blocks[2], stride=2)\n",
    "        #      (64, 8, 8)\n",
    "        self.layer4 = self._make_layer(block, 128, num_blocks[3], stride=2)\n",
    "        #      (128,4, 4)\n",
    "        self.convbn5 = nn.Sequential(\n",
    "            nn.Conv2d(128,128,kernel_size=4,stride=1,padding=0),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        #      (128,1, 1)\n",
    "        # transform to 128, then\n",
    "        self.linear1 = nn.Linear(int(128*block.expansion),   int(128*block.expansion/2))\n",
    "        self.linear2 = nn.Linear(int(128*block.expansion/2), int(128*block.expansion/4))\n",
    "        self.linear3 = nn.Linear(int(128*block.expansion/4), int(128*block.expansion/8))\n",
    "        self.linear4 = nn.Linear(int(128*block.expansion/8), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(geometricPad(x,self.pad))))\n",
    "        out = F.relu(self.bn2(self.conv2(geometricPad(out,self.pad))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.relu(self.convbn5(out))\n",
    "        #out = F.avg_pool2d(out, out.shape[2:4])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.linear1(out))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = F.relu(self.linear3(out))\n",
    "        out = self.linear4(out)\n",
    "        return out\n",
    "\n",
    "#    # I'm not sure why I need to implement cpu/cuda myself, train works somehow\n",
    "#    \n",
    "#    def cpu(self):\n",
    "#        super(GeomCNN, self).cpu()\n",
    "#        for module in self._feature:\n",
    "#            module.cpu()\n",
    "#        for module in self._classifier:\n",
    "#            module.cpu()\n",
    "#        return self\n",
    "#    \n",
    "#    def cuda(self):\n",
    "#        super(GeomCNN, self).cuda()\n",
    "#        for module in self._feature:\n",
    "#            module.cuda()\n",
    "#        for module in self._classifier:\n",
    "#            module.cuda()\n",
    "#        return self\n",
    "\n",
    "def ResNetGeom18(num_classes):\n",
    "    return ResNetGeom(BasicGeomBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLOB:\n",
    "    pass\n",
    "blob=BLOB()\n",
    "blob.net       = ResNetGeom18(3).cuda() # construct ResNet for 2 class classification, use GPU\n",
    "# just the training weights is ~700MiB\n",
    "blob.criterion = torch.nn.CrossEntropyLoss() # use softmax loss to define an error\n",
    "blob.optimizer = torch.optim.Adam(blob.net.parameters()) # use Adam optimizer algorithm\n",
    "blob.softmax   = torch.nn.Softmax(dim=1) # not for training, but softmax score for each class\n",
    "blob.prefix    = '20200708-03-IWCD-ResNetGeom-02-e-mu-gamma'\n",
    "blob.epoch     = 0.\n",
    "blob.iteration = 0\n",
    "blob.data      = None # data for training/analysis\n",
    "blob.label     = None # label for training/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_state(blob, 60752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = ['e','μ','γ']\n",
    "Nrows = 5\n",
    "for r in range(Nrows):\n",
    "    Nplot = 6\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "\n",
    "    blob.net.eval()\n",
    "    test_data = next(iter(test_loader))\n",
    "    blob.data,blob.label = test_data[0:2]\n",
    "    blob.data  = blob.data[0:Nplot,:,:,:]\n",
    "    blob.label = blob.label[0:Nplot]\n",
    "    \n",
    "    blob.formatted_data = torch.as_tensor(blob.data).cuda()#[torch.as_tensor(d).cuda() for d in blob.data]\n",
    "    blob.formatted_data = blob.formatted_data.permute(0,3,1,2)\n",
    "    \n",
    "    out = blob.net(blob.formatted_data)\n",
    "    prediction = torch.argmax(out,dim=-1)\n",
    "    \n",
    "    for ev in range(Nplot):\n",
    "        im = axes[ev].imshow(np.log(blob.data[ev,:,:,0]+0.5))\n",
    "        #imshowRdBu(axes[2*ev+qt], blob.formatted_data.grad[ev,qt,:,:].cpu())\n",
    "        correct = (blob.label[ev] == prediction[ev])\n",
    "        axes[ev].set_title('%s pred: %s, true: %s' % ('✔︎' if correct else '✖︎', labelNames[blob.label[ev]], labelNames[prediction[ev]]))\n",
    "        #cbar = fig.colorbar(im, ax=axes[0])\n",
    "    plt.show()\n",
    "    \n",
    "    blob.formatted_data.requires_grad = True\n",
    "    for case in [0,1,2]:\n",
    "        if blob.formatted_data.grad is not None:\n",
    "            blob.formatted_data.grad.zero_()\n",
    "        out = torch.log(blob.softmax(blob.net(blob.formatted_data)))\n",
    "\n",
    "        activation = torch.zeros(out.shape)\n",
    "        activation[:,case] = +1.\n",
    "        out.backward(activation.cuda())\n",
    "\n",
    "        fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "        for ev in range(Nplot):\n",
    "            imshowRdBu(axes[ev], blob.formatted_data.grad[ev,0,:,:].cpu())\n",
    "        axes[0].set_title('d/dx p(%s)' % (labelNames[case]))\n",
    "        plt.show();\n",
    "    \n",
    "    if blob.formatted_data.grad is not None:\n",
    "        blob.formatted_data.grad.zero_()\n",
    "    out = torch.log(blob.softmax(blob.net(blob.formatted_data)))\n",
    "\n",
    "    activation = torch.zeros(out.shape)\n",
    "    activation[:,0] = +1.\n",
    "    activation[:,2] = -1.\n",
    "    out.backward(activation.cuda())\n",
    "\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "    for ev in range(Nplot):\n",
    "        imshowRdBu(axes[ev], blob.formatted_data.grad[ev,0,:,:].cpu())\n",
    "    axes[0].set_title('d/dx [p(%s) - p(%s)]' % (labelNames[0],labelNames[2]))\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "    del test_data\n",
    "    del blob.data\n",
    "    del blob.label\n",
    "    del blob.formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just look at the output of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = F.relu(self.bn1(self.conv1(geometricPad(x,self.pad))))\n",
    "# out = F.relu(self.bn2(self.conv2(geometricPad(out,self.pad))))\n",
    "# out = self.layer1(out)\n",
    "# out = self.layer2(out)\n",
    "# out = self.layer3(out)\n",
    "# out = self.layer4(out)\n",
    "# out = F.relu(self.convbn5(out))\n",
    "# out = out.view(out.size(0), -1)\n",
    "# out = F.relu(self.linear1(out))\n",
    "# out = F.relu(self.linear2(out))\n",
    "# out = F.relu(self.linear3(out))\n",
    "# out = self.linear4(out)\n",
    "\n",
    "\n",
    "\n",
    "Nplot = 6\n",
    "fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "\n",
    "blob.net.eval()\n",
    "test_data = next(iter(test_loader))\n",
    "blob.data,blob.label = test_data[0:2]\n",
    "blob.data  = blob.data[0:Nplot,:,:,:]\n",
    "blob.label = blob.label[0:Nplot]\n",
    "\n",
    "blob.formatted_data = torch.as_tensor(blob.data).cuda()#[torch.as_tensor(d).cuda() for d in blob.data]\n",
    "blob.formatted_data = blob.formatted_data.permute(0,3,1,2)\n",
    "\n",
    "for ev in range(Nplot):\n",
    "    im = axes[ev].imshow(np.log(blob.data[ev,:,:,0]+0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbn1 = F.relu(blob.net.bn1(blob.net.conv1(geometricPad(blob.formatted_data,blob.net.pad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(convbn1.shape[1]):\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "    for ev in range(Nplot):\n",
    "        imshowRdBu(axes[ev], convbn1[ev,r,:,:].cpu().detach())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbn2 = F.relu(blob.net.bn2(blob.net.conv2(geometricPad(convbn1,blob.net.pad))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(convbn2.shape[1]):\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "    for ev in range(Nplot):\n",
    "        imshowRdBu(axes[ev], convbn2[ev,r,:,:].cpu().detach())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = blob.net.layer1(convbn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(layer1.shape[1]):\n",
    "    fig, axes = plt.subplots(1, Nplot, figsize=(16,3),facecolor='w')\n",
    "    for ev in range(Nplot):\n",
    "        imshowRdBu(axes[ev], layer1[ev,r,:,:].cpu().detach())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
